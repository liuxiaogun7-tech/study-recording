# study-recording
神经网络：一种模仿大脑、由多层“神经元”组成的、能通过数据学习规律的数学架构。
深度学习：使用特别多层的神经网络，让机器能够直接从海量数据中自动学习极其复杂的模式和特征的一种方法/技术。
人工智能的定义：人工智能就是要让机器的行为看起来就像是人所表现出的智能行为一样．
目前，人工智能的主要领域大体上可以分为以下几个方面：
（1） 感知：模拟人的感知能力，对外部刺激信息（视觉和语音等）进行感知和加工．主要研究领域包括语音信息处理和计算机视觉等．
（2） 学习：模拟人的学习能力，主要研究如何从样例或从与环境的交互中进行学习．主要研究领域包括监督学习、无监督学习和强化学习等．
（3） 认知：模拟人的认知能力，主要研究领域包括知识表示、自然语言理解、推理、规划、决策等．
当我们用机器学习来解决实际任务时，会面对多种多样的数据形式，比如声音、图像、文本等．不同数据的特征构造方式差异很大．对于图像这类数据，我们
可以很自然地将其表示为一个连续的向量． 将图像数据表示为向方法有很多种，比如直接将一幅图像的所有像素值（灰度值或RGB值）组成一个连续向量．
而对于文本数据，因为其一般由离散符号组成，并且每个符号在计算机内部都表示为无意义的编码，所以通常很难找到合适的表示方式．因此，在实际任务中使用机器学习模型一般会包含以下几个步骤（如图1.2所示）：
（1） 数据预处理：对数据的原始形式进行初步的数据清理（比如去掉一些有缺失特征的样本，或去掉一些冗余的数据特征等）和加工（对数值特征进行缩放和归一化等），并构建成可用于训练机器学习模型的数据集．
（2） 特征提取：从数据的原始特征中提取一些对特定机器学习任务有用的高质量特征．比如在图像分类中提取边缘、尺度不变特征变换（Scale InvariantFeature Transform，SIFT）特征，在文本分类中去除停用词等．
（3） 特征转换：对特征进行进一步的加工，比如降维和升维． 很多特征转换方法也都是机器学习方法．降维包括特征抽取（Feature Extraction）和特征选择（Feature Selection）两种途径．常用的特征转换方法有主成分分析（Principal Components Analysis，PCA）线性判别分析（Linear Discriminant Analysis，LDA）等．
（4） 预测：机器学习的核心部分，学习一个函数并进行预测．
原始数据 数据预处理 特征提取 特征转换 预测 结果特征处理 浅层学习
上述流程中，每步特征处理以及预测一般都是分开进行的．传统的机器学习模型主要关注最后一步，即构建预测函数．但是实际操作过程中，不同预测模型的性能相差不多，而前三步中的特征处理对最终系统的准确性有着十分关键的作用．特征处理一般都需要人工干预完成，利用人类的经验来选取好的特征，并最终提高机器学习系统的性能．因此，很多的机器学习问题变成了特征工程（Feature Engineering）问题．开发一个机器学习系统的主要工作量都消耗在了预处理、特征提取以及特征转换上。
输入信息转换为有效的特征，或者更一般性地称为表示（Representation）．如果有一种算法可以自动地学习出有效的特征，并提高最终机器学习模型的性能，那么这种学习就可以叫作表
示学习（Representation Learning）。
在表示学习中，有两个核心问题：一是“什么是一个好的表示”；二是“如何学习到好的表示”

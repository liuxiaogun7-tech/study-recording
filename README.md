# study-recording
神经网络：一种模仿大脑、由多层“神经元”组成的、能通过数据学习规律的数学架构。
深度学习：使用特别多层的神经网络，让机器能够直接从海量数据中自动学习极其复杂的模式和特征的一种方法/技术。

人工智能的定义：人工智能就是要让机器的行为看起来就像是人所表现出的智能行为一样．
目前，人工智能的主要领域大体上可以分为以下几个方面：
（1） 感知：模拟人的感知能力，对外部刺激信息（视觉和语音等）进行感知和加工．主要研究领域包括语音信息处理和计算机视觉等．
（2） 学习：模拟人的学习能力，主要研究如何从样例或从与环境的交互中进行学习．主要研究领域包括监督学习、无监督学习和强化学习等．
（3） 认知：模拟人的认知能力，主要研究领域包括知识表示、自然语言理解、推理、规划、决策等．

当我们用机器学习来解决实际任务时，会面对多种多样的数据形式，比如声音、图像、文本等．不同数据的特征构造方式差异很大．对于图像这类数据，我们可以很自然地将其表示为一个连续的向量． 将图像数据表示为向方法有很多种，比如直接将一幅图像的所有像素值（灰度值或RGB值）组成一个连续向量．而对于文本数据，因为其一般由离散符号组成，并且每个符号在计算机内部都表示为无意义的编码，所以通常很难找到合适的表示方式．因此，在实际任务中使用机器学习模型一般会包含以下几个步骤（如图1.2所示）：
（1） 数据预处理：对数据的原始形式进行初步的数据清理（比如去掉一些有缺失特征的样本，或去掉一些冗余的数据特征等）和加工（对数值特征进行缩放和归一化等），并构建成可用于训练机器学习模型的数据集．
（2） 特征提取：从数据的原始特征中提取一些对特定机器学习任务有用的高质量特征．比如在图像分类中提取边缘、尺度不变特征变换（Scale InvariantFeature Transform，SIFT）特征，在文本分类中去除停用词等．
（3） 特征转换：对特征进行进一步的加工，比如降维和升维． 很多特征转换方法也都是机器学习方法．降维包括特征抽取（Feature Extraction）和特征选择（Feature Selection）两种途径．常用的特征转换方法有主成分分析（Principal Components Analysis，PCA）线性判别分析（Linear Discriminant Analysis，LDA）等．
（4） 预测：机器学习的核心部分，学习一个函数并进行预测．

传统机器学习流程：
数据预处理 → 2. 特征提取 → 3. 特征转换 → 4. 预测模型
问题：依赖人工特征工程，且特征与模型目标可能不一致。

表示学习与深度学习
输入信息转换为有效的特征，或者更一般性地称为表示（Representation）．如果有一种算法可以自动地学习出有效的特征，并提高最终机器学习模型的性能，那么这种学习就可以叫作表示学习（Representation Learning）。
在表示学习中，有两个核心问题：一是“什么是一个好的表示”；二是“如何学习到好的表示”
在机器学习中，我们经常使用两种方式来表示特征：局部表示（Local Representation）和分布式表示（Distributed Representation）．
以颜色表示为例，我们可以用很多词来形容不同的颜色1，除了基本的“红”“蓝”“绿”“白”“黑”等之外，还有很多以地区或物品命名的，比如“中国红”“天蓝色”“咖啡色”“琥珀色”等．如果要在计算机中表示颜色，一般有两种表示方法．
一种表示颜色的方法是以不同名字来命名不同的颜色，这种表示方式叫作局部表示，也称为离散表示或符号表示．局部表示通常可以表示为one-hot 向量的形式．
One-Hot向量（独热编码向量）是一种用于表示离散型数据（如类别、符号、单词等）的简单且常用的数值化表示方法。
